{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "eb4d880b-17db-4c3c-925b-619399ade6f1",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import (\n",
        "    MulticlassClassificationEvaluator,\n",
        "    BinaryClassificationEvaluator,\n",
        ")\n",
        "from pyspark.ml.feature import Bucketizer, StringIndexer\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%run \"Common\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ML processing parameters\n",
        "`filesystem_endpoint`: The Azure Synapse storage account and container hosting the data.\n",
        "\n",
        "`data_folder`: The path to the folder on the Azure Synapse storage account containing the CSV file to process.\n",
        "\n",
        "`csv_file_name`: The CSV file to process.\n",
        "\n",
        "`algorithm`: The ML algorithm to use to train, test, and generate predictions. See the `MLAlgorithm` class defined in the `Common` notebook for a list of algorithms.\n",
        "\n",
        "`train_pct`: The percentage of data to use for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "csv_file_name = \"StarReconNoneEdgesWithHops.csv\"\n",
        "filesystem_endpoint = \"smtcrbsynfs@smtcrbsyndl.dfs.core.windows.net\"\n",
        "data_folder = \"/data/uwf\"\n",
        "\n",
        "algorithm = MLAlgorithm.NB\n",
        "train_pct = 0.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "file_path = f\"{data_folder}/{csv_file_name}\"\n",
        "dataset = file_path.split(\"/\")[-1]\n",
        "conn_df = load_csv(filesystem_endpoint, file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train, test, and generate predictions.\n",
        "\n",
        "This cell runs the algoithm on the dataset for all permutations of feature columns.\n",
        "\n",
        "This cell also saves the algorithm's metrics, including the confusion matrix. See the schema in the `Common` notebook to see exactly which results are collected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "result_df = spark.createDataFrame([], schema=schema)\n",
        "\n",
        "target_cols = [\"Tactic\"]\n",
        "\n",
        "all_cols = [\n",
        "    \"From\",\n",
        "    \"To\",\n",
        "    \"Avg_Duration\",\n",
        "    \"Total_Duration\",\n",
        "    \"Avg_Bytes\",\n",
        "    \"Total_Bytes\",\n",
        "    \"Count\",\n",
        "    \"Hop_Count\",\n",
        "]\n",
        "\n",
        "cols_combinations = []\n",
        "\n",
        "for r in range(1, len(all_cols) + 1):\n",
        "    cols_combinations.extend(list(itertools.combinations(all_cols, r)))\n",
        "\n",
        "cols_combinations_len = len(cols_combinations)\n",
        "\n",
        "for i, combination in enumerate(cols_combinations):\n",
        "    print(f\"Iteration {i+1} of {cols_combinations_len}\")\n",
        "\n",
        "    drop_cols = [col for col in all_cols if col not in combination]\n",
        "    additional_drop_cols = [\"Id\"]\n",
        "    drop_cols = drop_cols + additional_drop_cols\n",
        "\n",
        "    print(f\"Feature columns: {combination}\")\n",
        "    print(f\"Dropped columns: {drop_cols}\")\n",
        "\n",
        "    iter_df = conn_df.drop(*drop_cols)\n",
        "    iter_df = iter_df.na.drop(how=\"any\")\n",
        "\n",
        "    numeric_cols = [\n",
        "        name\n",
        "        for name, types in iter_df.dtypes\n",
        "        if types == \"int\" or types == \"double\" or types == \"bigint\"\n",
        "    ]\n",
        "\n",
        "    string_cols = [name for name, types in iter_df.dtypes if types == \"string\"]\n",
        "\n",
        "    indexers = [\n",
        "        StringIndexer(inputCol=column, outputCol=column + \"_processed\").fit(iter_df)\n",
        "        for column in string_cols\n",
        "    ]\n",
        "\n",
        "    numeric_bucketing = [\n",
        "        Bucketizer(\n",
        "            splits=[-float(\"inf\"), 10, 100, float(\"inf\")],\n",
        "            inputCol=x,\n",
        "            outputCol=x + \"_processed\",\n",
        "        )\n",
        "        for x in numeric_cols\n",
        "    ]\n",
        "\n",
        "    stages_ = indexers + numeric_bucketing\n",
        "\n",
        "    iter_df = Pipeline(stages=stages_).fit(iter_df).transform(iter_df)\n",
        "\n",
        "    feature_cols = []\n",
        "    for col, types in iter_df.dtypes:\n",
        "        if \"_processed\" in col:\n",
        "            if not target_cols[0] in col:\n",
        "                feature_cols.append(col)\n",
        "\n",
        "    assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "    iter_df = assembler.transform(iter_df)\n",
        "\n",
        "    train, test = iter_df.randomSplit([train_pct, 1 - train_pct], seed=1234)\n",
        "    label_col = target_cols[0] + \"_processed\"\n",
        "\n",
        "    predictions = run_ml_algorithm(\n",
        "        algorithm, feature_cols, label_col, iter_df, train_pct\n",
        "    )\n",
        "\n",
        "    predictions_and_labels = predictions.select([\"prediction\", label_col])\n",
        "\n",
        "    metrics = MulticlassMetrics(predictions_and_labels.rdd.map(tuple))\n",
        "    mc_evaluator = MulticlassClassificationEvaluator(\n",
        "        labelCol=label_col, predictionCol=\"prediction\"\n",
        "    )\n",
        "    accuracy = mc_evaluator.evaluate(predictions)\n",
        "\n",
        "    bin_evaluator = BinaryClassificationEvaluator(\n",
        "        rawPredictionCol=\"prediction\", labelCol=label_col, metricName=\"areaUnderROC\"\n",
        "    )\n",
        "    auc_roc = bin_evaluator.evaluate(predictions)\n",
        "\n",
        "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "\n",
        "    confusion_matrix_flattened = list(confusion_matrix.flatten().astype(str))\n",
        "\n",
        "    feature_col_str = \"&\".join(combination)\n",
        "\n",
        "    try:\n",
        "        precision = metrics.precision(1.0)\n",
        "    except:\n",
        "        precision = metrics.weightedPrecision\n",
        "\n",
        "    recall = metrics.recall(0)\n",
        "    fmeasure = metrics.fMeasure(0.0, 2.0)\n",
        "\n",
        "    try:\n",
        "        fprate = metrics.falsePositiveRate(1.0)\n",
        "    except:\n",
        "        fprate = metrics.weightedFalsePositiveRate\n",
        "\n",
        "    confusion_matrix_values = [float(x) for x in confusion_matrix_flattened]\n",
        "\n",
        "    if len(confusion_matrix_values) == 1:\n",
        "        confusion_matrix_values = (confusion_matrix_values[0], 0.0, 0.0, 0.0)\n",
        "    else:\n",
        "        confusion_matrix_values = tuple(confusion_matrix_values)\n",
        "\n",
        "    result_metrics = (\n",
        "        feature_col_str,\n",
        "        accuracy,\n",
        "        precision,\n",
        "        recall,\n",
        "        fmeasure,\n",
        "        fprate,\n",
        "        auc_roc,\n",
        "    ) + confusion_matrix_values\n",
        "\n",
        "    result_df = result_df.union(spark.createDataFrame([result_metrics], schema=schema))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save results\n",
        "\n",
        "The results are saved to the Azure Synapse Storage in the same folder as the input data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "69750a06-0b37-4441-9bf8-3c8216d9eae0",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [],
      "source": [
        "save_df_to_csv(\n",
        "    result_df,\n",
        "    filesystem_endpoint,\n",
        "    f\"{data_folder}/{algorithm.value}_results_{dataset}.csv\",\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
